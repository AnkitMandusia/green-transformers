{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    # Upgrade pip\n",
        "!pip install --upgrade pip --quiet\n",
        "\n",
        "# Install/upgrade required libraries\n",
        "!pip install torch --quiet\n",
        "!pip install torchvision --quiet\n",
        "!pip install torchaudio --quiet\n",
        "!pip install transformers==4.33.1 --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install codecarbon --quiet\n",
        "!pip install numpy==1.26.4 --quiet\n",
        "!pip install pandas --quiet\n",
        "!pip install tqdm\n"
      ],
      "metadata": {
        "id": "KDzp4INBTvSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2cb924-6da4-4eef-fb09-5f052bb326c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[1;31merror\u001b[0m: \u001b[1mfailed-wheel-build-for-install\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Failed to build installable wheels for some pyproject.toml based projects\n",
            "\u001b[31mâ•°â”€>\u001b[0m tokenizers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.38.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification,  DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from transformers.models.bert.modeling_bert import BertAttention, BertIntermediate, BertOutput\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertModel\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers.data.data_collator import default_data_collator\n",
        "import logging\n",
        "import warnings\n",
        "import random\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from codecarbon import OfflineEmissionsTracker\n",
        "import math\n",
        "\n",
        "# --- Configuration ---\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"codecarbon\").setLevel(logging.WARNING)\n",
        "DEVICE_CONFIG = {\n",
        "    'optimize_for_gpu': True,\n",
        "    'mixed_precision': True\n",
        "}\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() and DEVICE_CONFIG['optimize_for_gpu'] else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "DATASETS = {\n",
        "    'glue_sst2': {'name': 'glue', 'config': 'sst2', 'split': 'validation'},\n",
        "    'glue_mrpc': {'name': 'glue', 'config': 'mrpc', 'split': 'validation'},\n",
        "    'glue_rte': {'name': 'glue', 'config': 'rte', 'split': 'validation'}\n",
        "}\n",
        "MAX_SAMPLES = 5000\n",
        "WATER_USAGE_FACTORS = {\"average_l_per_kwh\": 1.8}\n",
        "CARBON_INTENSITY = 250  # gCO2e/kWh\n",
        "GLUE_TASKS_TO_RUN = ['sst2', 'mrpc', 'rte']\n",
        "BATCH_SIZE = 16\n",
        "SEQ_LEN = 128\n",
        "NUM_LAYERS = 1\n",
        "TIME_STEPS = 8  # Reduced from 16\n",
        "PATIENCE = 2  # Early stopping patience\n",
        "\n",
        "\n",
        "default_data_collator = lambda x: {k: torch.stack([torch.tensor(f[k]) for f in x]) for k in x[0]}\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def get_device():\n",
        "    device = torch.device(DEVICE)\n",
        "    if DEVICE == \"cuda\":\n",
        "        try:\n",
        "            print(f\"âœ“ Using GPU: {torch.cuda.get_device_name(0)} (CUDA)\")\n",
        "        except Exception:\n",
        "            print(\"âœ“ Using GPU (name unknown)\")\n",
        "        if DEVICE_CONFIG['mixed_precision']:\n",
        "            print(\"âœ“ Mixed precision (FP16) enabled.\")\n",
        "    else:\n",
        "        print(f\"âœ“ Using CPU\")\n",
        "    return device\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def tensor_to_spikes(tensor, time_steps=TIME_STEPS):\n",
        "    \"\"\"Converts a normalized tensor to a spike train with sparsity.\"\"\"\n",
        "    device = tensor.device\n",
        "    dtype = tensor.dtype\n",
        "    random_tensor = torch.rand(*tensor.shape, time_steps, device=device, dtype=dtype)\n",
        "    spikes = (random_tensor < tensor.unsqueeze(-1)).to(dtype)\n",
        "    # Introduce sparsity: only keep top 80% of spikes\n",
        "    threshold = torch.quantile(spikes.float(), 0.2, dim=-1, keepdim=True)\n",
        "    spikes = spikes * (spikes >= threshold).to(dtype)\n",
        "    return spikes\n",
        "\n",
        "def spikes_to_tensor(spikes):\n",
        "    \"\"\"Converts a spike train back to a tensor by averaging over the time dimension.\"\"\"\n",
        "    return torch.mean(spikes, dim=-1)\n",
        "\n",
        "# --- Optimized Spiking Self-Attention ---\n",
        "class SpikingSelfAttention(nn.Module):\n",
        "    \"\"\"Optimized SNN-based self-attention with sparsity and reduced time steps.\"\"\"\n",
        "    def __init__(self, hidden_dim, num_heads, device=None, sparsity=0.5):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.device = device or DEVICE\n",
        "        self.sparsity = sparsity\n",
        "        self.query_layer = nn.Linear(hidden_dim, hidden_dim).to(self.device)\n",
        "        self.key_layer = nn.Linear(hidden_dim, hidden_dim).to(self.device)\n",
        "        self.value_layer = nn.Linear(hidden_dim, hidden_dim).to(self.device)\n",
        "        self.output_layer = nn.Linear(hidden_dim, hidden_dim).to(self.device)\n",
        "        print(\"âœ“ Initialized optimized SNN attention module with sparsity\")\n",
        "\n",
        "    def forward(self, spike_input):\n",
        "        input_tensor = spikes_to_tensor(spike_input)\n",
        "        target_dtype = next(self.query_layer.parameters()).dtype\n",
        "        if input_tensor.dtype != target_dtype:\n",
        "            input_tensor = input_tensor.to(target_dtype)\n",
        "        query = self.query_layer(input_tensor)\n",
        "        key = self.key_layer(input_tensor)\n",
        "        value = self.value_layer(input_tensor)\n",
        "        attention_weights = torch.softmax(torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.hidden_dim), dim=-1)\n",
        "        # Apply sparsity to attention weights\n",
        "        threshold = torch.quantile(attention_weights, self.sparsity, dim=-1, keepdim=True)\n",
        "        attention_weights = attention_weights * (attention_weights >= threshold).to(attention_weights.dtype)\n",
        "        attention_output = torch.matmul(attention_weights, value)\n",
        "        output = self.output_layer(attention_output)\n",
        "        return tensor_to_spikes(output)\n",
        "\n",
        "# --- Optimized Hybrid Layers ---\n",
        "class HybridBertLayer(nn.Module):\n",
        "    \"\"\"Optimized hybrid layer for BERT with dynamic SNN attention usage.\"\"\"\n",
        "    def __init__(self, original_layer, device=None, sparsity=0.5):\n",
        "        super().__init__()\n",
        "        self.device = device or DEVICE\n",
        "        self.original_layer = original_layer\n",
        "        attention_module = original_layer.attention\n",
        "        config = attention_module.self.query.in_features\n",
        "        num_heads = attention_module.self.num_attention_heads\n",
        "        self.snn_attention = SpikingSelfAttention(hidden_dim=config, num_heads=num_heads, device=self.device, sparsity=sparsity)\n",
        "        self.use_snn = True\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_values=None,\n",
        "        output_attentions=False,\n",
        "        output_hidden_states=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        norm = torch.norm(hidden_states, dim=-1).mean()\n",
        "        self.use_snn = norm > 0.5\n",
        "        if self.use_snn:\n",
        "            attention_output = self.original_layer.attention.output.LayerNorm(hidden_states)\n",
        "            input_spikes = tensor_to_spikes(attention_output)\n",
        "            snn_attention_output_tensor = spikes_to_tensor(self.snn_attention(input_spikes))\n",
        "            attention_output = snn_attention_output_tensor + hidden_states\n",
        "        else:\n",
        "            attention_output = self.original_layer.attention(hidden_states, attention_mask, head_mask)[0]\n",
        "        intermediate_output = self.original_layer.intermediate(attention_output)\n",
        "        layer_output = self.original_layer.output(intermediate_output, attention_output)\n",
        "        return (layer_output,)\n",
        "\n",
        "class HybridDistilBertLayer(nn.Module):\n",
        "    \"\"\"Optimized hybrid layer for DistilBERT with dynamic SNN attention usage.\"\"\"\n",
        "    def __init__(self, original_layer, device=None, sparsity=0.5):\n",
        "        super().__init__()\n",
        "        self.device = device or DEVICE\n",
        "        self.original_layer = original_layer\n",
        "        config = original_layer.attention.q_lin.in_features\n",
        "        num_heads = original_layer.attention.n_heads\n",
        "        self.snn_attention = SpikingSelfAttention(hidden_dim=config, num_heads=num_heads, device=self.device, sparsity=sparsity)\n",
        "        self.ffn = original_layer.ffn\n",
        "        self.sa_layer_norm = original_layer.sa_layer_norm\n",
        "        self.output_layer_norm = original_layer.output_layer_norm\n",
        "        self.use_snn = True\n",
        "\n",
        "    def forward(self, x, attn_mask=None, head_mask=None, output_attentions=False):\n",
        "        norm = torch.norm(x, dim=-1).mean()\n",
        "        self.use_snn = norm > 0.5\n",
        "        if self.use_snn:\n",
        "            normed_states = self.sa_layer_norm(x)\n",
        "            input_spikes = tensor_to_spikes(normed_states)\n",
        "            attention_spikes = self.snn_attention(input_spikes)\n",
        "            attention_output_tensor = spikes_to_tensor(attention_spikes)\n",
        "            attention_output = attention_output_tensor + x\n",
        "        else:\n",
        "            attention_output = self.original_layer(x, attn_mask=attn_mask, head_mask=head_mask, output_attentions=output_attentions)[0]\n",
        "        ffn_input = self.output_layer_norm(attention_output)\n",
        "        layer_output = self.ffn(ffn_input)\n",
        "        return (layer_output,)\n",
        "\n",
        "# --- Build Hybrid Model ---\n",
        "def build_hybrid_neuromorphic_model(device, model_type=\"bert\", task_type=\"classification\", num_layers=1, debug=False):\n",
        "    \"\"\"Builds an optimized hybrid neuromorphic BERT or DistilBERT model.\"\"\"\n",
        "    print(f\"\\nðŸ—ï¸ Building Optimized Hybrid Neuromorphic {model_type.capitalize()} Model for {task_type}...\")\n",
        "    if model_type == \"bert\":\n",
        "        if task_type == \"classification\":\n",
        "            base_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported task_type {task_type} for BERT\")\n",
        "        original_layers = base_model.bert.encoder.layer\n",
        "        layer_class = HybridBertLayer\n",
        "    elif model_type == \"distilbert\":\n",
        "        if task_type == \"classification\":\n",
        "            base_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported task_type {task_type} for DistilBERT\")\n",
        "        original_layers = base_model.distilbert.transformer.layer\n",
        "        layer_class = HybridDistilBertLayer\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model_type {model_type}\")\n",
        "\n",
        "    class HybridModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.transformer = base_model.to(device)\n",
        "            self.model_type = model_type\n",
        "            self.task_type = task_type\n",
        "            self.debug = debug\n",
        "            for i in range(min(num_layers, len(original_layers))):\n",
        "                original_layers[-(i + 1)] = layer_class(original_layers[-(i + 1)], device=device, sparsity=0.5)\n",
        "            self.config = base_model.config\n",
        "            self.transformer.gradient_checkpointing_enable()\n",
        "\n",
        "        def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, **kwargs):\n",
        "            inputs = {}\n",
        "            if input_ids is not None:\n",
        "                inputs[\"input_ids\"] = input_ids\n",
        "            if attention_mask is not None:\n",
        "                inputs[\"attention_mask\"] = attention_mask\n",
        "            if token_type_ids is not None and self.model_type == \"bert\":\n",
        "                inputs[\"token_type_ids\"] = token_type_ids\n",
        "            outputs = self.transformer(**inputs, **kwargs)\n",
        "            if self.debug:\n",
        "                print(f\"[Hybrid Layers] Logits norm: {outputs.logits.norm().item():.4f}\")\n",
        "            return outputs\n",
        "\n",
        "    model = HybridModel()\n",
        "    print(f\"âœ“ Successfully created optimized hybrid neuromorphic {model_type.capitalize()} model for {task_type}.\")\n",
        "    return model\n",
        "\n",
        "# --- Data Loading ---\n",
        "def get_dataloaders(model_type, seq_len, batch_size):\n",
        "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    def preprocess_glue_sst2(examples):\n",
        "        enc = tokenizer(examples[\"sentence\"], padding=\"max_length\", max_length=seq_len, truncation=True)\n",
        "        return {\"input_ids\": enc[\"input_ids\"], \"attention_mask\": enc[\"attention_mask\"], \"token_type_ids\": enc[\"token_type_ids\"], \"labels\": examples[\"label\"]}\n",
        "\n",
        "    def preprocess_glue_mrpc(examples):\n",
        "        enc = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], padding=\"max_length\", max_length=seq_len, truncation=True)\n",
        "        return {\"input_ids\": enc[\"input_ids\"], \"attention_mask\": enc[\"attention_mask\"], \"token_type_ids\": enc[\"token_type_ids\"], \"labels\": examples[\"label\"]}\n",
        "\n",
        "    def preprocess_glue_rte(examples):\n",
        "        enc = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], padding=\"max_length\", max_length=seq_len, truncation=True)\n",
        "        return {\"input_ids\": enc[\"input_ids\"], \"attention_mask\": enc[\"attention_mask\"], \"token_type_ids\": enc[\"token_type_ids\"], \"labels\": examples[\"label\"]}\n",
        "\n",
        "    try:\n",
        "        glue_sst2_train_data = load_dataset(\"glue\", \"sst2\", split=f\"train[:{MAX_SAMPLES}]\")\n",
        "        glue_sst2_validation_data = load_dataset(\"glue\", \"sst2\", split=f\"validation[:{MAX_SAMPLES}]\")\n",
        "        glue_mrpc_train_data = load_dataset(\"glue\", \"mrpc\", split=f\"train[:{5000}]\")\n",
        "        glue_mrpc_validation_data = load_dataset(\"glue\", \"mrpc\", split=f\"validation[:{5000}]\")\n",
        "        glue_rte_train_data = load_dataset(\"glue\", \"rte\", split=f\"train[:{2490}]\")\n",
        "        glue_rte_validation_data = load_dataset(\"glue\", \"rte\", split=f\"validation[:{277}]\")\n",
        "\n",
        "        glue_sst2_train_data = glue_sst2_train_data.map(preprocess_glue_sst2, batched=True, remove_columns=['sentence', 'idx', 'label'])\n",
        "        glue_sst2_validation_data = glue_sst2_validation_data.map(preprocess_glue_sst2, batched=True, remove_columns=['sentence', 'idx', 'label'])\n",
        "        glue_mrpc_train_data = glue_mrpc_train_data.map(preprocess_glue_mrpc, batched=True, remove_columns=['sentence1', 'sentence2', 'idx', 'label'])\n",
        "        glue_mrpc_validation_data = glue_mrpc_validation_data.map(preprocess_glue_mrpc, batched=True, remove_columns=['sentence1', 'sentence2', 'idx', 'label'])\n",
        "        glue_rte_train_data = glue_rte_train_data.map(preprocess_glue_rte, batched=True, remove_columns=['sentence1', 'sentence2', 'idx', 'label'])\n",
        "        glue_rte_validation_data = glue_rte_validation_data.map(preprocess_glue_rte, batched=True, remove_columns=['sentence1', 'sentence2', 'idx', 'label'])\n",
        "\n",
        "        glue_sst2_train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"])\n",
        "        glue_sst2_validation_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"])\n",
        "        glue_mrpc_train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"])\n",
        "        glue_mrpc_validation_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"])\n",
        "        glue_rte_train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"])\n",
        "        glue_rte_validation_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"])\n",
        "\n",
        "        dataloaders = {\n",
        "            'glue_sst2_train': DataLoader(glue_sst2_train_data, batch_size=batch_size, shuffle=True, collate_fn=default_data_collator),\n",
        "            'glue_sst2_validation': DataLoader(glue_sst2_validation_data, batch_size=batch_size, shuffle=False, collate_fn=default_data_collator),\n",
        "            'glue_mrpc_train': DataLoader(glue_mrpc_train_data, batch_size=batch_size, shuffle=True, collate_fn=default_data_collator),\n",
        "            'glue_mrpc_validation': DataLoader(glue_mrpc_validation_data, batch_size=batch_size, shuffle=False, collate_fn=default_data_collator),\n",
        "            'glue_rte_train': DataLoader(glue_rte_train_data, batch_size=batch_size, shuffle=True, collate_fn=default_data_collator),\n",
        "            'glue_rte_validation': DataLoader(glue_rte_validation_data, batch_size=batch_size, shuffle=False, collate_fn=default_data_collator),\n",
        "        }\n",
        "        mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
        "        return dataloaders, tokenizer, mask_token_id, batch_size, seq_len\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ get_dataloaders failed: {e}. Returning empty dataloaders.\")\n",
        "        empty_data = {\n",
        "            \"input_ids\": torch.zeros((0, seq_len), dtype=torch.long),\n",
        "            \"attention_mask\": torch.zeros((0, seq_len), dtype=torch.long),\n",
        "            \"token_type_ids\": torch.zeros((0, seq_len), dtype=torch.long),\n",
        "            \"labels\": torch.tensor([], dtype=torch.long)\n",
        "        }\n",
        "        empty_dataset = Dataset.from_dict(empty_data)\n",
        "        empty_dataloader = DataLoader(empty_dataset, batch_size=batch_size, collate_fn=default_data_collator)\n",
        "        empty_dataloaders = {\n",
        "            'glue_sst2_train': empty_dataloader, 'glue_sst2_validation': empty_dataloader,\n",
        "            'glue_mrpc_train': empty_dataloader, 'glue_mrpc_validation': empty_dataloader,\n",
        "            'glue_rte_train': empty_dataloader, 'glue_rte_validation': empty_dataloader,\n",
        "        }\n",
        "        mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
        "        return empty_dataloaders, tokenizer, mask_token_id, batch_size, seq_len\n",
        "\n",
        "# --- Fine-Tuning with Early Stopping ---\n",
        "def fine_tune(model, train_dataloader, val_dataloader, device, epochs=1, task_type=\"classification\", patience=PATIENCE):\n",
        "    \"\"\"Fine-tunes the model with gradient checkpointing, cosine annealing LR, and early stopping.\"\"\"\n",
        "    model.train()\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs * len(train_dataloader))\n",
        "    loss_fct = torch.nn.CrossEntropyLoss()\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_train_loss = 0\n",
        "        for batch in tqdm(train_dataloader, desc=f\"Fine-tuning epoch {epoch+1}\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"labels\"]}\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(**inputs)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            logits = outputs.logits\n",
        "            loss = loss_fct(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader) if len(train_dataloader) > 0 else 0\n",
        "        print(f\"Epoch {epoch+1}, Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_dataloader, desc=f\"Validating epoch {epoch+1}\"):\n",
        "                inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"labels\"]}\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "                loss = loss_fct(logits, labels)\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_dataloader) if len(val_dataloader) > 0 else 0\n",
        "        print(f\"Epoch {epoch+1}, Average Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "            print(f\"New best validation loss: {best_val_loss:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"No improvement in validation loss. Patience counter: {patience_counter}/{patience}\")\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "                model.load_state_dict(best_model_state)\n",
        "                break\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "    return best_val_loss\n",
        "\n",
        "# --- Evaluation ---\n",
        "def evaluate_classification(model, dataloader, device, is_bert=True):\n",
        "    \"\"\"Evaluates the model on classification tasks.\"\"\"\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    predictions_list, labels_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask', 'token_type_ids']}\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            predictions_list.extend(predictions.cpu().numpy())\n",
        "            labels_list.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0.0\n",
        "    f1 = f1_score(labels_list, predictions_list, average='weighted')\n",
        "    return {'accuracy': accuracy, 'f1': f1}\n",
        "\n",
        "\n",
        "\n",
        "# --- Experiment Runner ---\n",
        "def run_experiment(model, model_name, dataloaders, device, is_bert, batch_size, seq_len, task_type, run_sst2=True, run_mrpc=True, run_rte=True):\n",
        "    \"\"\"Runs an optimized experiment with performance metrics.\"\"\"\n",
        "    results = {\n",
        "        'model_name': model_name,\n",
        "        'batch_size': batch_size,\n",
        "        'seq_length': seq_len,\n",
        "        'task_type': task_type,\n",
        "        'accuracy_metrics': {},\n",
        "        'performance_metrics': {}\n",
        "    }\n",
        "    print(f\"\\n--- ðŸš€ Measuring Metrics for {model_name} ({task_type}) ---\")\n",
        "    start_time = time.time()\n",
        "    num_queries = 0\n",
        "    emissions_kwh = 0.0\n",
        "\n",
        "    tracker = OfflineEmissionsTracker(\n",
        "        project_name=f\"Experiment_{model_name.replace(' ', '_')}\",\n",
        "        measure_power_secs=1,\n",
        "        output_dir=\".\",\n",
        "        log_level='warning',\n",
        "        country_iso_code=\"USA\",\n",
        "        region=None\n",
        "    )\n",
        "    tracker.start()\n",
        "\n",
        "    try:\n",
        "        if run_sst2 and task_type == \"classification\":\n",
        "            print(\"\\n--- Fine-tuning on GLUE SST-2 ---\")\n",
        "            best_val_loss = fine_tune(model, dataloaders['glue_sst2_train'], dataloaders['glue_sst2_validation'], device, epochs=8, task_type=task_type)\n",
        "            print(f\"Best Validation Loss for SST-2: {best_val_loss:.4f}\")\n",
        "            print(\" Evaluating GLUE SST-2...\")\n",
        "            metrics = evaluate_classification(model, dataloaders['glue_sst2_validation'], device, is_bert)\n",
        "            results['accuracy_metrics']['sst2_accuracy'] = metrics['accuracy']\n",
        "            results['accuracy_metrics']['sst2_f1'] = metrics['f1']\n",
        "            num_queries += len(dataloaders['glue_sst2_validation'].dataset)\n",
        "            print(f\" SST-2 Accuracy: {metrics['accuracy']:.4f}, F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "        if run_mrpc and task_type == \"classification\":\n",
        "            print(\"\\n--- Fine-tuning on GLUE MRPC ---\")\n",
        "            best_val_loss = fine_tune(model, dataloaders['glue_mrpc_train'], dataloaders['glue_mrpc_validation'], device, epochs=5, task_type=task_type)\n",
        "            print(f\"Best Validation Loss for MRPC: {best_val_loss:.4f}\")\n",
        "            print(\" Evaluating GLUE MRPC...\")\n",
        "            metrics = evaluate_classification(model, dataloaders['glue_mrpc_validation'], device, is_bert)\n",
        "            results['accuracy_metrics']['mrpc_accuracy'] = metrics['accuracy']\n",
        "            results['accuracy_metrics']['mrpc_f1'] = metrics['f1']\n",
        "            num_queries += len(dataloaders['glue_mrpc_validation'].dataset)\n",
        "            print(f\" MRPC Accuracy: {metrics['accuracy']:.4f}, F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "        if run_rte and task_type == \"classification\":\n",
        "            print(\"\\n--- Fine-tuning on GLUE RTE ---\")\n",
        "            best_val_loss = fine_tune(model, dataloaders['glue_rte_train'], dataloaders['glue_rte_validation'], device, epochs=3, task_type=task_type)\n",
        "            print(f\"Best Validation Loss for RTE: {best_val_loss:.4f}\")\n",
        "            print(\" Evaluating GLUE RTE...\")\n",
        "            metrics = evaluate_classification(model, dataloaders['glue_rte_validation'], device, is_bert)\n",
        "            results['accuracy_metrics']['rte_accuracy'] = metrics['accuracy']\n",
        "            results['accuracy_metrics']['rte_f1'] = metrics['f1']\n",
        "            num_queries += len(dataloaders['glue_rte_validation'].dataset)\n",
        "            print(f\" RTE Accuracy: {metrics['accuracy']:.4f}, F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "        emissions_kwh = tracker.stop() or 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"ðŸš¨ Experiment failed for {model_name}: {e}\")\n",
        "        if tracker._running:\n",
        "            emissions_kwh = tracker.stop() or 0.0\n",
        "        else:\n",
        "            emissions_kwh = 0.0\n",
        "\n",
        "    total_duration_s = time.time() - start_time\n",
        "    total_tokens_processed = num_queries * seq_len\n",
        "    total_carbon_g = emissions_kwh * CARBON_INTENSITY\n",
        "    results['performance_metrics'] = {\n",
        "        'latency_ms_query': (total_duration_s / num_queries) * 1000 if num_queries > 0 else 0,\n",
        "        'throughput_tokens_sec': total_tokens_processed / total_duration_s if total_duration_s > 0 else 0,\n",
        "        'energy_wh_token': (emissions_kwh * 1000) / total_tokens_processed if total_tokens_processed > 0 else 0,\n",
        "        'sci_gco2e_query': total_carbon_g / num_queries if num_queries > 0 else 0,\n",
        "        'wue_avg_liters_query': (emissions_kwh * WATER_USAGE_FACTORS['average_l_per_kwh']) / num_queries if num_queries > 0 else 0,\n",
        "        'total_emissions_kwh': emissions_kwh\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- Results for {model_name} ---\")\n",
        "    print(f\" Duration: {total_duration_s:.2f}s | Emissions: {total_carbon_g / 1000:.6f} kg CO2eq | Queries: {num_queries}\")\n",
        "    print(json.dumps(results, indent=2))\n",
        "    print(\"-\" * 40)\n",
        "    return results\n",
        "\n",
        "# --- Main Experiment ---\n",
        "if __name__ == \"__main__\":\n",
        "    DEVICE = get_device()\n",
        "    set_seed(42)\n",
        "    batch_size = 16\n",
        "    seq_len = 128\n",
        "    num_layers = 1\n",
        "\n",
        "    # Initialize results list\n",
        "    all_results = []\n",
        "\n",
        "    # Define model configurations\n",
        "    model_configs = [\n",
        "       # {'model_type': 'distilbert', 'task_type': 'classification', 'is_hybrid': False, 'name': 'Baseline_DistilBERT_Classification'},\n",
        "      {'model_type': 'distilbert', 'task_type': 'classification', 'is_hybrid': True, 'name': 'Hybrid_DistilBERT_Classification'},\n",
        "       #{'model_type': 'bert', 'task_type': 'classification', 'is_hybrid': False, 'name': 'Baseline_BERT_Classification'},\n",
        "       # {'model_type': 'bert', 'task_type': 'classification', 'is_hybrid': True, 'name': 'Hybrid_BERT_Classification'},\n",
        "    ]\n",
        "\n",
        "    # Run experiments for each task separately to avoid interference\n",
        "    for config in model_configs:\n",
        "        model_type = config['model_type']\n",
        "        task_type = config['task_type']\n",
        "        is_hybrid = config['is_hybrid']\n",
        "        #base_name = config['name']\n",
        "        model_name = config['name']\n",
        "\n",
        "        # Get dataloaders\n",
        "        dataloaders, _, _, _, _ = get_dataloaders(model_type=model_type, seq_len=seq_len, batch_size=batch_size)\n",
        "\n",
        "        # Run separate experiments for each task\n",
        "        # for task in GLUE_TASKS_TO_RUN:\n",
        "        #     model_name = f\"{base_name}_{task.upper()}\"\n",
        "        #     print(f\"\\n=== Running experiment for {model_name} ===\")\n",
        "\n",
        "            # Build fresh model for each task\n",
        "        if is_hybrid:\n",
        "\n",
        "          model = build_hybrid_neuromorphic_model(\n",
        "          device=DEVICE,\n",
        "          model_type=model_type,\n",
        "          task_type=task_type,\n",
        "          num_layers=num_layers )\n",
        "        else:\n",
        "          model = build_baseline_model(\n",
        "          device=DEVICE,\n",
        "          model_type=model_type,\n",
        "          task_type=task_type)\n",
        "\n",
        "\n",
        "            # Run experiment\n",
        "        results = run_experiment(\n",
        "                model=model,\n",
        "                model_name=model_name,\n",
        "                dataloaders=dataloaders,\n",
        "                device=DEVICE,\n",
        "                is_bert=(model_type == 'bert'),\n",
        "                batch_size=batch_size,\n",
        "                seq_len=seq_len,\n",
        "                task_type=task_type,\n",
        "                  run_sst2=True, run_mrpc=True, run_rte=True\n",
        "            )\n",
        "        all_results.append(results)\n",
        "\n",
        "    # Save all results to a JSON file\n",
        "    with open('experiment_results.json', 'w') as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "\n",
        "    df_out = pd.json_normalize(all_results, sep='_')\n",
        "    df_out.to_csv('Hybrid_DistilBERTs.csv', index=False)\n",
        "    print(\"âœ… CSV saved to 'hybrid_gpu_neuromorphic_results.csv'\")\n",
        "    print(\"\\nAll experiments completed. Results saved.\")"
      ],
      "metadata": {
        "id": "h8ok8o2TUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a150a621e1f44943bd346ae84426e015",
            "6e88482c6c3b40c7aa98941211c7c218",
            "477441d07d8c49ac9ed4536776607e29",
            "71c989ac8fbb4bc7909e1be79fd16c23",
            "e727eb159fdc41a3ad746d63070f32ac",
            "f78b961307614abeaef1b87297ce19b0"
          ]
        },
        "outputId": "1fbc5d33-62c7-4575-aa92-11f1b057982f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "âœ“ Using GPU: Tesla T4 (CUDA)\n",
            "âœ“ Mixed precision (FP16) enabled.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a150a621e1f44943bd346ae84426e015",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e88482c6c3b40c7aa98941211c7c218",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "477441d07d8c49ac9ed4536776607e29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71c989ac8fbb4bc7909e1be79fd16c23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e727eb159fdc41a3ad746d63070f32ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2490 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f78b961307614abeaef1b87297ce19b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/277 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ—ï¸ Building Optimized Hybrid Neuromorphic Distilbert Model for classification...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[codecarbon WARNING @ 19:44:15] Multiple instances of codecarbon are allowed to run at the same time.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Initialized optimized SNN attention module with sparsity\n",
            "âœ“ Successfully created optimized hybrid neuromorphic Distilbert model for classification.\n",
            "\n",
            "--- ðŸš€ Measuring Metrics for Hybrid_DistilBERT_Classification (classification) ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 19:44:16] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 19:44:16] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon WARNING @ 19:44:16] No CPU tracking mode found. Falling back on CPU constant mode.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fine-tuning on GLUE SST-2 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuning epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [01:09<00:00,  4.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Training Loss: 0.3618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:04<00:00, 12.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Validation Loss: 0.3080\n",
            "New best validation loss: 0.3080\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuning epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [01:10<00:00,  4.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Training Loss: 0.1341\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:04<00:00, 12.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Validation Loss: 0.2998\n",
            "New best validation loss: 0.2998\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuning epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [01:12<00:00,  4.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Training Loss: 0.0463\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:04<00:00, 11.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Validation Loss: 0.4516\n",
            "No improvement in validation loss. Patience counter: 1/2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuning epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [01:13<00:00,  4.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Training Loss: 0.0201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:04<00:00, 11.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Validation Loss: 0.5171\n",
            "No improvement in validation loss. Patience counter: 2/2\n",
            "Early stopping triggered after 4 epochs.\n",
            "Best Validation Loss for SST-2: 0.2998\n",
            " Evaluating GLUE SST-2...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:04<00:00, 11.70it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " SST-2 Accuracy: 0.8750, F1: 0.8748\n",
            "\n",
            "--- Fine-tuning on GLUE MRPC ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuning epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:54<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Training Loss: 0.6038\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00, 11.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Validation Loss: 0.4713\n",
            "New best validation loss: 0.4713\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuning epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:54<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Training Loss: 0.3963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00, 11.72it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Validation Loss: 0.4057\n",
            "New best validation loss: 0.4057\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuning epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:54<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Training Loss: 0.1506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00, 11.70it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Validation Loss: 0.4826\n",
            "No improvement in validation loss. Patience counter: 1/2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuning epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:54<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Training Loss: 0.0439\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00, 11.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Validation Loss: 0.6286\n",
            "No improvement in validation loss. Patience counter: 2/2\n",
            "Early stopping triggered after 4 epochs.\n",
            "Best Validation Loss for MRPC: 0.4057\n",
            " Evaluating GLUE MRPC...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00, 11.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " MRPC Accuracy: 0.8333, F1: 0.8266\n",
            "\n",
            "--- Fine-tuning on GLUE RTE ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:37<00:00,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Training Loss: 0.7388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 11.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Validation Loss: 0.6877\n",
            "New best validation loss: 0.6877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:37<00:00,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Training Loss: 0.6668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 12.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Validation Loss: 0.6913\n",
            "No improvement in validation loss. Patience counter: 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:37<00:00,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Training Loss: 0.5639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 11.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Validation Loss: 0.7108\n",
            "No improvement in validation loss. Patience counter: 2/2\n",
            "Early stopping triggered after 3 epochs.\n",
            "Best Validation Loss for RTE: 0.6877\n",
            " Evaluating GLUE RTE...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 11.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " RTE Accuracy: 0.5596, F1: 0.5588\n",
            "\n",
            "--- Results for Hybrid_DistilBERT_Classification ---\n",
            " Duration: 656.69s | Emissions: 0.002041 kg CO2eq | Queries: 1557\n",
            "{\n",
            "  \"model_name\": \"Hybrid_DistilBERT_Classification\",\n",
            "  \"batch_size\": 16,\n",
            "  \"seq_length\": 128,\n",
            "  \"task_type\": \"classification\",\n",
            "  \"accuracy_metrics\": {\n",
            "    \"sst2_accuracy\": 0.875,\n",
            "    \"sst2_f1\": 0.8748086772528624,\n",
            "    \"mrpc_accuracy\": 0.8333333333333334,\n",
            "    \"mrpc_f1\": 0.8266201217329038,\n",
            "    \"rte_accuracy\": 0.5595667870036101,\n",
            "    \"rte_f1\": 0.5588393516948126\n",
            "  },\n",
            "  \"performance_metrics\": {\n",
            "    \"latency_ms_query\": 421.76941088858365,\n",
            "    \"throughput_tokens_sec\": 303.48336483276404,\n",
            "    \"energy_wh_token\": 4.0963613490039166e-05,\n",
            "    \"sci_gco2e_query\": 0.0013108356316812533,\n",
            "    \"wue_avg_liters_query\": 9.438016548105022e-06,\n",
            "    \"total_emissions_kwh\": 0.008163884314110845\n",
            "  }\n",
            "}\n",
            "----------------------------------------\n",
            "âœ… CSV saved to 'hybrid_gpu_neuromorphic_results.csv'\n",
            "\n",
            "All experiments completed. Results saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNcEeWerJkmn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}